{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e6bd4f0-3d46-4da1-a101-22dfd61a9fe1",
   "metadata": {},
   "source": [
    "# Smart Document Retrieval\n",
    "<p>This notebook is being created to help understand the concepts behind smart document retrieval. The primary focus of the notebook is to illustrate the process of using a transformer model to embed text data into a numerical representation that can be used to calculating a similarity score as compared to a query string. Additionally we explore some of the architectual theory of a complete application.</p>\n",
    "<p>Smart Document Retrieval can be devided into the following key components:\n",
    "    <li>1) Document Management</li>\n",
    "    <li>2) Source Text Extraction</li>\n",
    "    <li>3) Source Text Storage</li>\n",
    "    <li>4) Source Text Embedding\n",
    "        <ul>\n",
    "            <li>4a) Model Selection</li>\n",
    "            <li>4b) Model Evaluation (TODO)</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>5) Source Embedding Storage and Management</li>\n",
    "    <li>6) Query String Embedding</li>\n",
    "    <li>7) Similarity Scoring and Ranking</li>\n",
    "    <li>8) Relance Classification (optional / TODO)</li>\n",
    "    <li>9) User interface (optional / TODO)</li>\n",
    "    <li>10) Advanced techniques (TODO)\n",
    "        <ul>\n",
    "            <li><a href='https://www.sbert.net/examples/applications/retrieve_rerank/README.html'>Retrieval and Re-Ranking - Bi-Encoders(Retrieval) and Cross-Encoders(Re-Ranker)</a></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9804333-81ef-4abd-b6d9-a2b82bcb48fd",
   "metadata": {},
   "source": [
    "## 1) Document Management\n",
    "<p>The exact manner you manage the documents/resources to use will be based on your use case and is beyond the scope of this notebook; however it is important to consider several items.\n",
    "    <li><b>Access</b>\n",
    "        <ul>\n",
    "            <li>With the application have continious access to source documents?</li>\n",
    "            <li>Will the application need privileged permissions?</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><b>Versioning</b>\n",
    "        <ul>\n",
    "            <li>Is there a document versioning process?</li>\n",
    "            <li>Are there duplicate/variations of a documents?</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><b>Document/Resource Types</b>\n",
    "        <ul>\n",
    "            <li>What type of document formats will be used? (eg. MS Word, Excel, Google Docs, Websites, Emails, Etc..)</li>\n",
    "            <li>Are there diffent format versions?</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be3d93e-51c3-4530-8662-8474e2c1568e",
   "metadata": {},
   "source": [
    "## 2) Source Text Extraction\n",
    "<p>The process for extracting the source text will vary by use case, we offer some things to consider during your design but there may be other considerations based on your requirements. The example dataset used in this notebook was extracted fromSource Text Storage USPTO patent XML files selecting just the abstract for embedding.\n",
    "    <li><b>Content Extraction - Technical</b>\n",
    "        <ul>\n",
    "            <li>How will you access the source text within the resource/document?</li>\n",
    "            <li>What libraries / tools will be needed to extract text?</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><b>Content Selection</b>\n",
    "        <ul>\n",
    "            <li>What parts of the document will be selected for extraction?(e.g. Subject Line, Executive Summary, Individual Sections, etc..)</li>\n",
    "            <li>If you would like the application to identify specific locations within a document that contain the relevant information you will need to extract source text at the same level.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><b>Content Quality</b>\n",
    "        <ul>\n",
    "            <li>Do you need to remove meta-data or file formatting components such as XML tags?</li>\n",
    "            <li>Are there errors that need to be fixed? (e.g. spelling, formatting)</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1556ad-8ef2-4c04-8d22-229c396760d4",
   "metadata": {},
   "source": [
    "## 3) Source Text Storage\n",
    "<p>The example dataset used in this notebook has been stored in a simple csv file format however if your usecase needs to scale to millions,billions,or more items a database may be benificial. One option could be to use MongoDB running in its own container to store the Source Text data.<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4e0ca33-9f08-4a85-b7ce-1974d3ee65cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the needed libraries & Modules\n",
    "\n",
    "# Import cudf. cudf is part of the NVIDIA RAPIDS datascience SDK and is used to store the dataframes \n",
    "# used in gpu memory.\n",
    "import cudf\n",
    "\n",
    "# Import SentenceTransformer and util from the HuggingFace sentence_transformer library which has\n",
    "# been pre-installed in this environment.\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Import smart_search_models. This module was created for this example to simplify the management of the \n",
    "# various models that can be used for the embedding process.\n",
    "import smart_search_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695299cc-bb30-4a1d-9ee8-0c504706a88b",
   "metadata": {},
   "source": [
    "### Loading Example Dataset\n",
    "<p>The dataset being used in this example is comprised of nearly 7,000 USPTO Patent submissions. It is important to note that the dataset has not been cleaned and contains incomplete abstract entrees, this is useful for understanding the performance of various models. Although having clean data is always prefered it is important to understand how the models will perform on incomplete data.</p>\n",
    "\n",
    "<p>The source text dataset is stored in plain text CSV file containing the source XML file name and the extracted Abstract text. This is an important step in the document retreival process. The method of storing the source text may vary based on your use case (e.g. CSV, JSON, MongoDB, etc..). We use CSV in this example for simplicity.</p>\n",
    "\n",
    "<b>Incomplete Examples</b>\n",
    "Listed below are just a couple examples of entrees with inclomplete abstracts. \n",
    "<li>data/xml/us10882359-20210105.xml - 'In a tire'</li>\n",
    "<li>data/xml/us10881285-20210105.xml - 'A method ('</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e8e6913-d9eb-4701-baf0-6ddd69ddd088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/xml/us10885437-20210105.xml</td>\n",
       "      <td>Security systems and methods for detecting int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/xml/us10884005-20210105.xml</td>\n",
       "      <td>The present invention provides biomarkers usef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/xml/us10887313-20210105.xml</td>\n",
       "      <td>The described technology provides a single sig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/xml/us10887088-20210105.xml</td>\n",
       "      <td>A computing device includes an interface confi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/xml/us10887228-20210105.xml</td>\n",
       "      <td>Techniques for enabling peer-to-peer transmiss...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           FileName  \\\n",
       "0  data/xml/us10885437-20210105.xml   \n",
       "1  data/xml/us10884005-20210105.xml   \n",
       "2  data/xml/us10887313-20210105.xml   \n",
       "3  data/xml/us10887088-20210105.xml   \n",
       "4  data/xml/us10887228-20210105.xml   \n",
       "\n",
       "                                            Abstract  \n",
       "0  Security systems and methods for detecting int...  \n",
       "1  The present invention provides biomarkers usef...  \n",
       "2  The described technology provides a single sig...  \n",
       "3  A computing device includes an interface confi...  \n",
       "4  Techniques for enabling peer-to-peer transmiss...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in the example dataset\n",
    "df = cudf.read_csv('abstracts.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d522c0a4-64de-45a1-a2d4-61ad96835051",
   "metadata": {},
   "source": [
    "## 4) Source Text Embedding\n",
    "<p>Historical methods for search involved simple <a href='https://en.wikipedia.org/wiki/Lexicography'>lexicographical</a> similarity pattern matching such as regex. Although methods such as lexical search can be useful for some use cases they have several disadvantages such as needing to specific the precise terms to search for. To improve search results it can be advantagous to search based on <a href='https://en.wikipedia.org/wiki/Semantic_similarity#:~:text=Semantic%20similarity%20is%20a%20metric,as%20opposed%20to%20lexicographical%20similarity.'>sematic similarity</a> using concepts rather than word for comparison.</p>\n",
    "\n",
    "<p>To be able to seach by concept we must be able to represent our data in the form of concepts. This is where <a href='https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)'>Transformers</a> come in. <a href='https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)'>Transformers</a> are a form of Machine Learning that can be applied to Natural Language Processing (NLP) where the models have been trained on extremely large datasets such as Wikipedia to develop the ability to represent input text as a highly dimensional numerical representation, this process is called <a href='https://vaclavkosar.com/ml/transformer-embeddings-and-tokenization'>embedding</a>. If this sounds complicated, don't worry the hard parts are all abstracted away for us, we just need to use the sentence transformer libriary. Although there are benefits of understanding how the models work, sometimes it can be just as valuable to show how easy they are to use and how impressive the results can be using off-the-shelf models. If greater accuracy is needed you can always <a href='https://www.sbert.net/docs/training/overview.html'>train transformers</a> on your own datasets to improve their capabilities.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030e3398-8aa2-49c4-b71f-f4da717f990d",
   "metadata": {},
   "source": [
    "### 4a) Model Selection\n",
    "<p> There are a large number of models to choose from on <a href='https://huggingface.co/'>HuggingFace</a> even for just the task of <a href='https://huggingface.co/models?pipeline_tag=sentence-similarity&sort=downloads'>Sentence Similarity</a>(>800 as of 11/2022). We have include a python module to help simplify organization and selection of a smaller subset of models to experiment with (~100). Using <a href='https://huggingface.co/'>HuggingFace</a> simplifies the process of downloading and running the various models, it is not the only way to consume Transformers but it was choosen as it is one of the easiest ways to get started.</p>\n",
    "    \n",
    "There are a number of areas to consider when selecting a model for a given task\n",
    "<li><b>Model Size</b> - Large models need more VRAM and can take longer to run but may be more 'accurate'</li>\n",
    "<li><b>Model Architecture</b> - Some models might be designed for specific use cases or finetuned for a given problem. If your use case is similar you might have high performance out of the box.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdea5866-924f-4d17-b9a4-70d9089a93d5",
   "metadata": {},
   "source": [
    "### 4b) Model Evaluation\n",
    "<p> TODO: Add content on steps to understand model performance</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6d366e-220d-4917-9395-a40fdc9dba92",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading the Model\n",
    "<p>Loading the model is a simple as passing the model name as an input argument to create a model object. If the model isn't available locally it will be downloaded automatically. One of the hardest part of working with HuggingFace is keeping track of all the models available. You can view all the models availabe for <a href='https://huggingface.co/models?pipeline_tag=sentence-similarity&sort=downloads'>Sentence Similarity</a> and copy the name into the code or to simplify things we have created a very basic python module <a href='smart_search_models.py'>smart_search_models.py</a> to hold model names.</p>\n",
    "\n",
    "<details>\n",
    "  <summary>SentenceTransformer Parameters</summary>\n",
    "<li><b>model_name_or_path</b> – If it is a filepath on disc, it loads the model from that path. If it is not a path, it first tries to download a pre-trained SentenceTransformer model. If that fails, tries to construct a model from Huggingface models repository with that name.</li>\n",
    "<li><b>modules</b> – This parameter can be used to create custom SentenceTransformer models from scratch.</li>\n",
    "<li><b>device</b> – Device (like ‘cuda’ / ‘cpu’) that should be used for computation. If None, checks if a GPU can be used.</li>\n",
    "<li><b>cache_folder</b> – Path to store models</li>\n",
    "<li><b>use_auth_token</b> – HuggingFace authentication token to download private models.</li>\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f99bb47e-f036-4371-921c-1f4e730ad56f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many models are in the module\n",
    "len(smart_search_models.sentence_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77d3181b-83c9-4868-80f9-e88194092c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: 'all-MiniLM-L12-v2'\n"
     ]
    }
   ],
   "source": [
    "# Select and load model.\n",
    "# Note: If a given model hasn't been used since the container has been loaded it will be downloaded automatically.\n",
    "model_name = smart_search_models.sentence_models[6]\n",
    "print(\"Loading model: '{}'\".format(model_name))\n",
    "model = SentenceTransformer(model_name,cache_folder='./models/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3c4a8b-190e-46c2-9af3-d1b37a0f6aa0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Source Text Embedding\n",
    "<p>To embed the source text we can pass the entire column of our dataset into the model object in a single line of code as shown in the cell block below.</p>\n",
    "\n",
    "<p>A couple important items to note here:\n",
    "    <li>You only need to embed the source text once for a given model. Depending on the your use case you may wish to database the embeddings for later use, just remember to keep track of the model used for embedding and the source document.</li>\n",
    "    <li>As each model will embed the input text differently you need to ensure the source text and query text were embedded using the same model. If you choose to database or store your embedding for later just be sure to track which models where used for the embedding as you will likely get unexpected results if comparing embedding from different models.</li>\n",
    "    </p>\n",
    "\n",
    "<details>\n",
    "  <summary>encode Parameters</summary>\n",
    "    <li><b>sentences</b> – the sentences to embed</li>\n",
    "    <li><b>batch_size</b> – the batch size used for the computation</li>\n",
    "    <li><b>show_progress_bar</b> – Output a progress bar when encode sentences</li>\n",
    "    <li><b>output_value</b> – Default sentence_embedding, to get sentence embeddings. Can be set to token_embeddings to get wordpiece token embeddings. Set to None, to get all output values</li>\n",
    "    <li><b>convert_to_numpy</b> – If true, the output is a list of numpy vectors. Else, it is a list of pytorch tensors.</li>\n",
    "    <li><b>convert_to_tensor</b> – If true, you get one large tensor as return. Overwrites any setting from convert_to_numpy</li>\n",
    "    <li><b>device</b> – Which torch.device to use for the computation</li>\n",
    "    <li><b>normalize_embeddings</b> – If set to true, returned vectors will have length 1. In that case, the faster dot-product (util.dot_score) instead of cosine similarity can be used.</li>\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef4bfb6a-55fa-430c-8709-6de1031cbe0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.8 s, sys: 1.22 s, total: 22 s\n",
      "Wall time: 5.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "source_embeddings = model.encode(df.Abstract.to_pandas(), convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3b6bc1-f0a3-4c1f-946f-529bba635dcd",
   "metadata": {},
   "source": [
    "## 6) Query String Embedding\n",
    "<p>Using the same model we then embed our query string to be used for comparison</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1c44b46-0319-4f84-8f58-d417b5684428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.46 ms, sys: 6.47 ms, total: 8.94 ms\n",
      "Wall time: 8.11 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Embed the query string\n",
    "query_string = 'datascience'\n",
    "query_embedding = model.encode(query_string,convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722045ab-8aad-4303-88ae-4663229769c5",
   "metadata": {},
   "source": [
    "## 7) Similarity Scoring and Ranking\n",
    "<p>Next we need to calculate the similarity between the to query embedding and all the source text embeddings. One of the most common approaches is to calculate the cosinse similarity. Again the complexities and math have been abstracted here with the <a href='https://www.sbert.net/docs/package_reference/util.html'>util.cos_sim</a> function.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d1fbabb-c332-44e6-a660-895343288bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.46 ms, sys: 144 µs, total: 4.6 ms\n",
      "Wall time: 3.89 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create a new dataframe to store the results.\n",
    "results_df = df.copy()\n",
    "\n",
    "#Compute cosine-similarities\n",
    "results_df['score'] = util.cos_sim(source_embeddings, query_embedding).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edfbf66a-aaee-4a71-9baf-30f83ac4f856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/xml/us10885055-20210105.xml</td>\n",
       "      <td>One or more datasets are received by a data wr...</td>\n",
       "      <td>[0.4848591983318329]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/xml/us10885120-20210105.xml</td>\n",
       "      <td>A search request relating to one or more datas...</td>\n",
       "      <td>[0.46172472834587097]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/xml/us10884402-20210105.xml</td>\n",
       "      <td>Sensor data is received characterizing operati...</td>\n",
       "      <td>[0.45607712864875793]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/xml/us10884574-20210105.xml</td>\n",
       "      <td>A computer displays a graphical user interface...</td>\n",
       "      <td>[0.4508618414402008]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/xml/us10887433-20210105.xml</td>\n",
       "      <td>Systems and methods are provided for segmentin...</td>\n",
       "      <td>[0.43512162566185]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           FileName  \\\n",
       "0  data/xml/us10885055-20210105.xml   \n",
       "1  data/xml/us10885120-20210105.xml   \n",
       "2  data/xml/us10884402-20210105.xml   \n",
       "3  data/xml/us10884574-20210105.xml   \n",
       "4  data/xml/us10887433-20210105.xml   \n",
       "\n",
       "                                            Abstract                  score  \n",
       "0  One or more datasets are received by a data wr...   [0.4848591983318329]  \n",
       "1  A search request relating to one or more datas...  [0.46172472834587097]  \n",
       "2  Sensor data is received characterizing operati...  [0.45607712864875793]  \n",
       "3  A computer displays a graphical user interface...   [0.4508618414402008]  \n",
       "4  Systems and methods are provided for segmentin...     [0.43512162566185]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the top ten results\n",
    "top_ten = results_df.nlargest(10,'score').reset_index(drop=True)\n",
    "top_ten.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "425652ab-a863-4a2c-9314-752227f8930a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The below Abstract resulted in a similarity score of [0.4848591983318329] \n",
      "\n",
      "One or more datasets are received by a data wrangling module and wrangled into a form that is computationally actionable by a user. At least some data from the one or more datasets are enriched by one or more data enrichment modules to generate an enriched form of at least some data corresponding to the one or more datasets that is computationally actionable by the user. The one or more datasets and the enriched form of the at least some data are processed by a signal detection module to identify relationships, anomalies, and/or patterns within the one or more datasets.\n"
     ]
    }
   ],
   "source": [
    "# Show the highest scoring Abstract\n",
    "print('The below Abstract resulted in a similarity score of {} \\n'.format(top_ten.score[0]))\n",
    "print(top_ten.Abstract[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83e1a0f-ac14-45cc-babd-856acd2416ab",
   "metadata": {},
   "source": [
    "### Additional Resources\n",
    "\n",
    "<li><a href='https://huggingface.co/'>HuggingFace</a></li>\n",
    "<li><a href='https://huggingface.co/models?pipeline_tag=sentence-similarity&sort=downloads'>Sentence Similarity Models</a></li>\n",
    "<li><a href='https://www.sbert.net/docs/usage/semantic_textual_similarity.html'>Sematic Textual Similarity</a></li>\n",
    "\n",
    "### Environment\n",
    "This notebook has been developed and tested on the following:\n",
    "<li>RAPIDS - rapidsai-core:22.10-cuda11.5-base-ubuntu20.04-py3.9</li>\n",
    "<li>Pytorch 1.12.1</li>\n",
    "<li>sentence-transformers</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd14244c-b098-4827-88af-baeb43483b00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
